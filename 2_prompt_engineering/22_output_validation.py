import asyncio
from async_config import client
from rich.console import Console
from rich.markdown import Markdown
import json
from jsonschema import validate, ValidationError

console = Console()
def is_json_and_conforms_to_schema(output_text:str, schema:dict)->bool:
    try:
        output_text = json.loads(output_text)
        validate(instance=output_text, schema=schema)
        return True
    except json.JSONDecodeError:
        console.print(Markdown("Output Validtion failed: not valid JSON"))
        return False
    except ValidationError as e:
        console.print(Markdown(f"Output Validation failed: Does nnot conform to schema Error {e}"))
        return False
    
def contains_blacklist_keywords(output_text:str, black_list:list[str])->bool:
    for keyword in black_list:
        if keyword in output_text.lower():
            console.print(f"Output validation failed: contains blacklist keywords '{keyword}'")
            return True
    return False

PRODUCT_SCHEMA = { 
    "type": "object", 
    "properties": { 
        "product_name": {"type": "string"}, 
        "price": {"type": "number"}, 
        "in_stock": {"type": "boolean"} 
    }, 
    "required": ["product_name", "price", "in_stock"] 
} 

CONTENT_BLACKLIST = ["password", "credit card", "social security number", "secret"] 

async def generate_and_validate_product_info(product_query:str):
    system_prompt = f""" 
        You are an assistant that provides product information in JSON format. 
        The JSON object must conform to this schema: 
        {json.dumps(PRODUCT_SCHEMA)} 
        Only provide information about the requested product. Do not include any other commentary. 
    """ 
    console.rule(f"\n--- Generating info for: {product_query} ---") 
    try: 
        response = await client.chat.completions.create(
            model="gpt-4.1-nano", 
            messages=[ 
                {"role": "system", "content": system_prompt}, 
                {"role": "user", "content": product_query} 
            ], 
            temperature=0.2, 
            response_format = {"type": "json_object"}, 
        )
        llm_output = response.choices[0].message.content
        console.print(Markdown(f"RAW LLM Output: {llm_output}"))
        if not is_json_and_conforms_to_schema(llm_output, PRODUCT_SCHEMA):
            console.print("Response is not valid JSON or doesnt not match schema. Discarding.")
            return None
        
        if contains_blacklist_keywords(llm_output, CONTENT_BLACKLIST):
            console.print("Response contains blacklisted keywords. Discarding.")
            return None
        
        console.print(Markdown("Output Validate Successfully"))
        return json.loads(llm_output)
    
    except Exception as e:
        console.print(f"An error occurred: {e}")
        return None
    
async def self_critique_example(initial_response:str):
    console.print(Markdown("\n--- Performing Self-Critique ---"))
    critique_prompt = f""" 
        You are a safety evaluation AI. Review the following text generated by another AI. 
        Is this text safe, polite, and does it avoid making harmful or biased statements? 
        If it is safe, respond with "SAFE". 
        If it is unsafe or problematic, respond with "UNSAFE" and briefly explain why. 
    
        Text to review: 
        --- 
        {initial_response} 
        --- 
    """ 
    try:
        critique_response = await client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[
                {"role": "system", "content": "You are an AI safety evaluator."}, 
                {"role": "user", "content": critique_prompt}
            ],
            temperature=0.0,
        )
        critique_result = critique_response.choices[0].message.content
        console.print(Markdown(f"Critique Result: {critique_result}"))
        return critique_result.startswith("SAFE")
    except Exception as e:
        console.print(f"An error occurred during critique: {e}")
        return False
    
async def main():
    valid_product_output = await generate_and_validate_product_info("SuperWidget Model X")

    if valid_product_output:
        console.print(f"Validate Product Info: {valid_product_output}")
    
    bad_llm_output_non_json = "Sorry, I cannot provide details for SuperGadget Z. It's a secret." 
    print(f"\n--- Validating simulated bad output (non-JSON): --- \n'{bad_llm_output_non_json}'") 
    if not is_json_and_conforms_to_schema(bad_llm_output_non_json, PRODUCT_SCHEMA): 
        print("Simulated bad output correctly identified as invalid.") 

    bad_llm_output_bad_keyword = '{"product_name": "TopSecretFile", "price": 100, "in_stock": true, "details": "Your new password is TopSecretFile"}' 
    print(f"\n--- Validating simulated bad output (bad keyword): --- \n'{bad_llm_output_bad_keyword}'") 
    if is_json_and_conforms_to_schema(bad_llm_output_bad_keyword, PRODUCT_SCHEMA): 

    # It might pass schema 
        if contains_blacklist_keywords(bad_llm_output_bad_keyword, CONTENT_BLACKLIST): 
            print("Simulated bad output (bad keyword) correctly identified.") 
    
    potentially_problematic_response = "All politicians are the same, honestly." 
    is_safe = await self_critique_example(potentially_problematic_response) 
    print(f"Is '{potentially_problematic_response}' safe according to self-critique? {is_safe}") 

    harmless_response = "The sky is blue." 
    is_safe = await self_critique_example(harmless_response) 
    print(f"Is '{harmless_response}' safe according to self-critique? {is_safe}") 

if __name__ == "__main__":
    asyncio.run(main())